{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dad02883-2644-4c02-9c94-9b5d3dae9656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pipeline: Bronze to Silver\n",
    "\n",
    "## Data Source\n",
    "\n",
    "- **Catalog Location:**  `workspace.hospital_bronze`\n",
    "- **Dimensional Tables:** `cities, departments, diagnoses, procedures, providers, insurance`\n",
    "- **Format:** Delta Lake Table\n",
    "\n",
    "\n",
    "## Destination\n",
    "\n",
    "- **Catalog Location:** `workspace.hospital_silver`\n",
    "- **Dimensional Tables:** `cities, departments, diagnoses, procedures, providers, insurance`\n",
    "- **Format:** Delta Lake Table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77fc2cb7-bf03-4689-bbb9-a7ebeaf62da9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daddf852-7fc7-4456-aa4c-d4e859bdc729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"dimensional_table\", \"\")\n",
    "dimensional_table = dbutils.widgets.get(\"dimensional_table\")\n",
    "\n",
    "assert dimensional_table, \"Missing required parameter: dimensional_table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f224b3a-91fb-4067-8555-b8003e284f4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks Storage\n",
    "catalog_name = \"workspace\"\n",
    "schema_silver = \"hospital_silver\"\n",
    "schema_bronze = \"hospital_bronze\"\n",
    "schema_gold = \"hospital_gold\"\n",
    "\n",
    "# data source path\n",
    "data_source = \"s3://buckethospitaldata/data_batching/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c63fe29a-7ca8-4098-a9d7-7031e36572f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_from_silver(dimensional_table):\n",
    "    dataframe = spark.readStream.table(f\"{catalog_name}.{schema_silver}.{dimensional_table}\")\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "def write_to_gold(dataframe, checkpoint_location: str, gold_table: str):\n",
    "    # Get existing target table schema\n",
    "    target_schema = spark.table(f\"{catalog_name}.{schema_gold}.{gold_table}\").schema\n",
    "    target_columns = [field.name for field in target_schema]\n",
    "\n",
    "    # Filter input DataFrame to only include columns that match the target table\n",
    "    common_columns = list(set(dataframe.columns) & set(target_columns))\n",
    "    df_filtered = dataframe.select(common_columns)\n",
    "\n",
    "    \n",
    "    # Write to the gold layer using writeStream\n",
    "    (\n",
    "        df_filtered.writeStream\n",
    "        .format(\"delta\")\n",
    "        .outputMode(\"append\")\n",
    "        .option(\"checkpointLocation\", checkpoint_location)\n",
    "        .trigger(once=True)\n",
    "        .toTable(f\"{catalog_name}.{schema_gold}.{gold_table}\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63067c9e-cd3c-40ca-8c62-2d036099652a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Load Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5abc3e41-498e-4584-a9fc-a3b10438ae24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0a1ad3e-0b08-4308-aed9-b2c405d71384",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "827cc558-0873-4095-a56e-333cf190a57c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if dimensional_table == 'cities':\n",
    "    print(f\"Preparing streaming write for '{dimensional_table}' table...\")\n",
    "\n",
    "    # config checkpoint and location in gold layer\n",
    "    checkpoint_location = f\"s3://buckethospitaldata/pipeline_checkpoints/data_batching/_checkpoints/gold/{dimensional_table}\"\n",
    "    gold_table = f\"dim_{dimensional_table}\"\n",
    "\n",
    "    # read from silver\n",
    "    df_cities = read_from_silver(dimensional_table).drop('rescued_data')\n",
    "\n",
    "    # write to gold\n",
    "    write_to_gold(df_cities, checkpoint_location, gold_table)\n",
    "\n",
    "    print(f\"Write to {gold_table} initiated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "393a368e-61a3-44a9-b193-4309603875e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83933604-f3c8-41f0-83b7-da3bb86b4dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if dimensional_table == 'departments':\n",
    "    print(f\"Preparing streaming write for '{dimensional_table}' table...\")\n",
    "\n",
    "    # config checkpoint and location in gold layer\n",
    "    checkpoint_location = f\"s3://buckethospitaldata/pipeline_checkpoints/data_batching/_checkpoints/gold/{dimensional_table}\"\n",
    "    gold_table = f\"dim_{dimensional_table}\"\n",
    "\n",
    "    # read from silver\n",
    "    df_departments = read_from_silver(dimensional_table).drop('rescued_data')\n",
    "\n",
    "    # write to gold\n",
    "    write_to_gold(df_departments, checkpoint_location, gold_table)\n",
    "\n",
    "    print(f\"Write to {gold_table} initiated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45edcfb5-a1ae-4f69-b159-c0d2b2b60e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93e2ee82-38ba-484d-86a4-abe56b7a2412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if dimensional_table == 'diagnoses':\n",
    "    print(f\"Preparing streaming write for '{dimensional_table}' table...\")\n",
    "\n",
    "    # config checkpoint and location in gold layer\n",
    "    checkpoint_location = f\"s3://buckethospitaldata/pipeline_checkpoints/data_batching/_checkpoints/gold/{dimensional_table}\"\n",
    "    gold_table = f\"dim_{dimensional_table}\"\n",
    "\n",
    "    # read from silver\n",
    "    df_diagnoses = read_from_silver(dimensional_table).drop('rescued_data')\n",
    "\n",
    "    # write to gold\n",
    "    write_to_gold(df_diagnoses, checkpoint_location, gold_table)\n",
    "\n",
    "    print(f\"Write to {gold_table} initiated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "572fccc5-20d8-4f89-9592-3304a4657485",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cfbecdc-1c0a-470b-bc18-76c1a64c5839",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if dimensional_table == 'insurance':\n",
    "    print(f\"Preparing streaming write for '{dimensional_table}' table...\")\n",
    "\n",
    "    # config checkpoint and location in gold layer\n",
    "    checkpoint_location = f\"s3://buckethospitaldata/pipeline_checkpoints/data_batching/_checkpoints/gold/{dimensional_table}\"\n",
    "    gold_table = f\"dim_{dimensional_table}\"\n",
    "\n",
    "    # read from silver\n",
    "    df_insurance = read_from_silver(dimensional_table).drop('rescued_data')\n",
    "\n",
    "    # write to gold\n",
    "    write_to_gold(df_insurance, checkpoint_location, gold_table)\n",
    "\n",
    "    print(f\"Write to {gold_table} initiated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f488c1e-aa6a-4551-bb0b-c204e2303c1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1d66d58-8c5a-41e1-8df7-cad1730683d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if dimensional_table == 'procedures':\n",
    "    print(f\"Preparing streaming write for '{dimensional_table}' table...\")\n",
    "\n",
    "    # config checkpoint and location in gold layer\n",
    "    checkpoint_location = f\"s3://buckethospitaldata/pipeline_checkpoints/data_batching/_checkpoints/gold/{dimensional_table}\"\n",
    "    gold_table = f\"dim_{dimensional_table}\"\n",
    "\n",
    "    # read from silver\n",
    "    df_procedures = read_from_silver(dimensional_table).drop('rescued_data')\n",
    "\n",
    "    # write to gold\n",
    "    write_to_gold(df_procedures, checkpoint_location, gold_table)\n",
    "\n",
    "    print(f\"Write to {gold_table} initiated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc0d4bda-cd4b-4ac5-bcc8-60cae65977e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eccc30d-2da5-44da-8fb7-3c1db0c09fc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if dimensional_table == 'providers':\n",
    "    print(f\"Preparing streaming write for '{dimensional_table}' table...\")\n",
    "\n",
    "    # config checkpoint and location in gold layer\n",
    "    checkpoint_location = f\"s3://buckethospitaldata/pipeline_checkpoints/data_batching/_checkpoints/gold/{dimensional_table}\"\n",
    "    gold_table = f\"dim_{dimensional_table}\"\n",
    "\n",
    "    # read from silver\n",
    "    df_providers = read_from_silver(dimensional_table).drop('rescued_data')\n",
    "\n",
    "    # write to gold\n",
    "    write_to_gold(df_providers, checkpoint_location, gold_table)\n",
    "\n",
    "    print(f\"Write to {gold_table} initiated.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4,
    "widgetLayout": [
     {
      "breakBefore": false,
      "name": "dimensional_table",
      "width": 166
     }
    ]
   },
   "notebookName": "pipeline_silver_to_gold_dimensions",
   "widgets": {
    "dimensional_table": {
     "currentValue": "procedures",
     "nuid": "fbf29984-0f75-41d7-bfb5-f0c3dd9cdfa7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "dimensional_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "dimensional_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
